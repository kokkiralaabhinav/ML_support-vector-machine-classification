{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMW0tEW9kTtb+gpXbJdJL8w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["SVM Classifier\n","\n","Equation of the Hyperplane:\n","\n","y = wx - b\n","\n","Gradient Descent:\n","\n","Gradient Descent is an optimization algorithm used for minimizing the loss function in various machine learning algorithms. It is used for updating the parameters of the learning model.\n","\n","w = w - α*dw\n","\n","b = b - α*db\n","\n","Learning Rate:\n","\n","Learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.\n","\n","Importing the Dependencies"],"metadata":{"id":"ac78M9JPyze1"}},{"cell_type":"code","source":["# importing numpy library\n","import numpy as np"],"metadata":{"id":"3RtkJtGoy1YZ","executionInfo":{"status":"ok","timestamp":1664158130752,"user_tz":-330,"elapsed":391,"user":{"displayName":"KOKKIRALA ABHINAV","userId":"02028495556914824936"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#Support Vector Machine Classifier\n","class SVM_classifier():\n","\n","\n","  # initiating the hyperparameters\n","  def __init__(self, learning_rate, no_of_iterations, lambda_parameter):\n","\n","    self.learning_rate = learning_rate\n","    self.no_of_iterations = no_of_iterations\n","    self.lambda_parameter = lambda_parameter\n","\n","\n","  \n","  # fitting the dataset to SVM Classifier\n","  def fit(self, X, Y):\n","\n","    # m  --> number of Data points --> number of rows\n","    # n  --> number of input features --> number of columns\n","    self.m, self.n = X.shape\n","\n","    # initiating the weight value and bias value\n","\n","    self.w = np.zeros(self.n)\n","\n","    self.b = 0\n","\n","    self.X = X\n","\n","    self.Y = Y\n","\n","    # implementing Gradient Descent algorithm for Optimization\n","\n","    for i in range(self.no_of_iterations):\n","      self.update_weights()\n","\n","\n","\n","  # function for updating the weight and bias value\n","  def update_weights(self):\n","\n","    # label encoding\n","    y_label = np.where(self.Y <= 0, -1, 1)\n","\n","\n","\n","    # gradients ( dw, db)\n","    for index, x_i in enumerate(self.X):\n","\n","      condition = y_label[index] * (np.dot(x_i, self.w) - self.b) >= 1\n","\n","      if (condition == True):\n","\n","        dw = 2 * self.lambda_parameter * self.w\n","        db = 0\n","\n","      else:\n","\n","        dw = 2 * self.lambda_parameter * self.w - np.dot(x_i, y_label[index])\n","        db = y_label[index]\n","\n","\n","      self.w = self.w - self.learning_rate * dw\n","\n","      self.b = self.b - self.learning_rate * db\n","\n","\n","\n","  # predict the label for a given input value\n","  def predict(self, X):\n","\n","    output = np.dot(X, self.w) - self.b\n","    \n","    predicted_labels = np.sign(output)\n","\n","    y_hat = np.where(predicted_labels <= -1, 0, 1)\n","\n","    return y_hat"],"metadata":{"id":"mS9Rdutuy4la","executionInfo":{"status":"ok","timestamp":1664158128281,"user_tz":-330,"elapsed":684,"user":{"displayName":"KOKKIRALA ABHINAV","userId":"02028495556914824936"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["mylist = [10,20,30,40,50]\n","for i, mylist_i in enumerate(mylist):\n","  print(i,mylist_i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBhxVOKZi1Ry","executionInfo":{"status":"ok","timestamp":1664158036217,"user_tz":-330,"elapsed":18,"user":{"displayName":"KOKKIRALA ABHINAV","userId":"02028495556914824936"}},"outputId":"58353f3c-a355-4d0e-f50c-cd0107e56b49"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["0 10\n","1 20\n","2 30\n","3 40\n","4 50\n"]}]}]}